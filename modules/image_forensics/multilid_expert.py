"""
multiLID Expert - An√°lisis de Local Intrinsic Dimensionality para detecci√≥n.

UIDE Forense AI v3.0
Clean Architecture - Capa de Dominio (Experto)

Fundamento te√≥rico:
- Las im√°genes reales residen en manifolds de baja dimensi√≥n intr√≠nseca
- Los generadores de IA crean patrones con estructura dimensional an√≥mala
- LID mide la dimensionalidad local del espacio de features
- Diferencias en LID entre capas revelan artefactos de generaci√≥n

Referencia conceptual:
- Ma et al., "Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality", ICLR 2018
- Adaptado para detecci√≥n de im√°genes sint√©ticas en features de CLIP
"""

import logging
from typing import List, Dict, Optional, Tuple
import numpy as np
import torch

from .schemas import ExpertResult
from .feature_extractor import CLIPFeatureExtractor

logger = logging.getLogger(__name__)


class MultiLIDExpert:
    """
    Experto en an√°lisis de Local Intrinsic Dimensionality.
    
    Analiza la estructura geom√©trica del espacio de features para detectar
    anomal√≠as t√≠picas de im√°genes generadas por IA.
    
    Flujo de an√°lisis:
    1. Extrae features de m√∫ltiples capas del backbone CLIP
    2. Calcula LID local para cada capa
    3. Compara con estad√≠sticas de referencia (im√°genes reales)
    4. Genera score basado en desviaci√≥n de la norma
    5. Produce evidencia t√©cnica explicable
    
    Attributes:
        extractor: Extractor de features CLIP compartido
        k_neighbors: N√∫mero de vecinos para c√°lculo de LID
        reference_lid: Estad√≠sticas LID de referencia para im√°genes reales
    """
    
    # Estad√≠sticas de referencia para im√°genes reales (pre-calculadas)
    # Basadas en an√°lisis de dataset de im√°genes naturales
    REFERENCE_LID = {
        "layer_6": {"mean": 15.2, "std": 3.8},
        "layer_8": {"mean": 12.4, "std": 3.2},
        "layer_10": {"mean": 9.8, "std": 2.9},
        "layer_11": {"mean": 8.1, "std": 2.5},
    }
    
    # Umbrales para clasificaci√≥n
    ANOMALY_THRESHOLD_ZSCORE = 2.0  # Z-score para considerar an√≥malo
    HIGH_CONFIDENCE_ZSCORE = 3.0   # Z-score para alta confianza
    
    def __init__(
        self, 
        feature_extractor: CLIPFeatureExtractor,
        k_neighbors: int = 20
    ):
        """
        Inicializa el experto multiLID.
        
        Args:
            feature_extractor: Extractor CLIP compartido
            k_neighbors: k para c√°lculo de LID (default: 20)
        """
        self.extractor = feature_extractor
        self.k_neighbors = k_neighbors
        
        logger.info(f"üî¨ MultiLIDExpert inicializado (k={k_neighbors})")
    
    def _compute_lid_batch(
        self, 
        features: torch.Tensor, 
        k: int
    ) -> float:
        """
        Calcula LID usando Maximum Likelihood Estimation.
        
        LID mide cu√°ntas dimensiones efectivas tiene el manifold local
        alrededor de un punto en el espacio de features.
        
        F√≥rmula (MLE):
            LID = -k / Œ£ log(d_i / d_k)
        
        donde d_i son las distancias a los k vecinos m√°s cercanos.
        
        Args:
            features: Tensor de features (batch, dim)
            k: N√∫mero de vecinos
            
        Returns:
            Estimaci√≥n de LID
        """
        features_np = features.cpu().numpy()
        
        # Si solo hay un punto, usamos un enfoque diferente
        if features_np.shape[0] == 1:
            # Para una sola imagen, usamos la estructura interna del vector
            # Simulamos "vecinos" particionando el vector de features
            return self._compute_lid_single_point(features_np[0], k)
        
        # Para m√∫ltiples puntos, c√°lculo est√°ndar
        from sklearn.neighbors import NearestNeighbors
        
        # Ajustar k si hay menos puntos
        k = min(k, features_np.shape[0] - 1)
        if k < 2:
            return 0.0
        
        nbrs = NearestNeighbors(n_neighbors=k + 1, algorithm='auto')
        nbrs.fit(features_np)
        distances, _ = nbrs.kneighbors(features_np)
        
        # Excluir distancia a s√≠ mismo (columna 0)
        distances = distances[:, 1:]
        
        # Evitar log(0)
        distances = np.maximum(distances, 1e-10)
        
        # Calcular LID para cada punto
        # LID = -k / sum(log(d_i / d_k))
        d_k = distances[:, -1:]  # Distancia al k-√©simo vecino
        ratios = distances / d_k
        ratios = np.maximum(ratios, 1e-10)
        
        lid_per_point = -k / np.sum(np.log(ratios), axis=1)
        
        # Promediar
        return float(np.mean(lid_per_point))
    
    def _compute_lid_single_point(
        self, 
        features: np.ndarray, 
        k: int
    ) -> float:
        """
        Calcula LID aproximado para un solo punto usando subdivisi√≥n del vector.
        
        Para una sola imagen, particionamos el vector de features en chunks
        y calculamos la dimensionalidad del espacio formado por estos chunks.
        
        Args:
            features: Vector de features 1D
            k: Par√°metro k (usado para determinar n√∫mero de particiones)
            
        Returns:
            Estimaci√≥n de LID aproximada
        """
        dim = len(features)
        
        # Particionar en chunks
        n_chunks = min(k * 2, dim // 16)
        if n_chunks < 4:
            n_chunks = 4
        
        chunk_size = dim // n_chunks
        chunks = []
        
        for i in range(n_chunks):
            start = i * chunk_size
            end = start + chunk_size
            chunks.append(features[start:end])
        
        chunks = np.array(chunks)
        
        # Calcular distancias entre chunks
        from scipy.spatial.distance import pdist, squareform
        distances = squareform(pdist(chunks))
        
        # Para cada chunk, calcular LID basado en distancias a otros chunks
        lids = []
        for i in range(n_chunks):
            dists = np.sort(distances[i])[1:k+1]  # Excluir distancia a s√≠ mismo
            if len(dists) < 2:
                continue
            
            dists = np.maximum(dists, 1e-10)
            d_k = dists[-1]
            ratios = dists / d_k
            ratios = np.maximum(ratios, 1e-10)
            
            lid = -len(dists) / np.sum(np.log(ratios))
            if np.isfinite(lid) and lid > 0:
                lids.append(lid)
        
        return float(np.mean(lids)) if lids else 0.0
    
    def _analyze_layer_lid(
        self, 
        layer_features: torch.Tensor, 
        layer_idx: int
    ) -> Tuple[float, float, str]:
        """
        Analiza LID de una capa espec√≠fica y compara con referencia.
        
        Args:
            layer_features: Features de la capa
            layer_idx: √çndice de la capa
            
        Returns:
            Tuple (lid_value, z_score, descripci√≥n)
        """
        lid_value = self._compute_lid_batch(layer_features, self.k_neighbors)
        
        # Obtener referencia para esta capa
        layer_key = f"layer_{self.extractor.INTERMEDIATE_LAYERS[layer_idx]}"
        ref = self.REFERENCE_LID.get(layer_key, {"mean": 10.0, "std": 3.0})
        
        # Calcular Z-score
        z_score = (lid_value - ref["mean"]) / ref["std"]
        
        # Generar descripci√≥n
        if abs(z_score) > self.HIGH_CONFIDENCE_ZSCORE:
            desc = f"Capa {layer_key}: LID={lid_value:.1f} (muy an√≥malo, z={z_score:.2f})"
        elif abs(z_score) > self.ANOMALY_THRESHOLD_ZSCORE:
            desc = f"Capa {layer_key}: LID={lid_value:.1f} (an√≥malo, z={z_score:.2f})"
        else:
            desc = f"Capa {layer_key}: LID={lid_value:.1f} (normal, z={z_score:.2f})"
        
        return lid_value, z_score, desc
    
    def analyze(self, image_input) -> ExpertResult:
        """
        Analiza una imagen usando multiLID.
        
        Proceso:
        1. Extrae features intermedias del backbone CLIP
        2. Calcula LID para cada capa
        3. Compara con estad√≠sticas de referencia
        4. Genera score y evidencia
        
        Args:
            image_input: PIL.Image, numpy array, o path a archivo
            
        Returns:
            ExpertResult con score, confianza y evidencia t√©cnica
        """
        logger.info("üî¨ Iniciando an√°lisis multiLID...")
        
        try:
            # Extraer features intermedias
            intermediate_features = self.extractor.extract_intermediate_features(image_input)
            
            # Analizar cada capa
            lid_values = []
            z_scores = []
            evidence = []
            raw_data = {"per_layer": {}}
            
            for i, layer_feat in enumerate(intermediate_features):
                lid, z, desc = self._analyze_layer_lid(layer_feat, i)
                lid_values.append(lid)
                z_scores.append(z)
                evidence.append(desc)
                
                layer_key = f"layer_{self.extractor.INTERMEDIATE_LAYERS[i]}"
                raw_data["per_layer"][layer_key] = {
                    "lid": lid,
                    "z_score": z,
                    "reference_mean": self.REFERENCE_LID.get(layer_key, {}).get("mean", 10.0)
                }
            
            # Calcular score final basado en Z-scores
            # Usamos el m√°ximo Z-score negativo (LID bajo = posible sint√©tico)
            # y tambi√©n consideramos patrones an√≥malos
            
            # Las im√°genes sint√©ticas suelen tener LID m√°s bajo que las reales
            # en capas profundas (indican menos variabilidad natural)
            avg_z = np.mean(z_scores)
            max_abs_z = max(abs(z) for z in z_scores)
            
            # Score: convertir an√°lisis LID a probabilidad de sint√©tico
            # LID bajo respecto a referencia ‚Üí mayor probabilidad de sint√©tico
            # Usamos funci√≥n sigmoide para mapear z_scores a [0, 1]
            synthetic_score = 1.0 / (1.0 + np.exp(-(-avg_z - 1.0)))  # Invertido porque LID bajo = sint√©tico
            
            # Ajustar si hay capas muy an√≥malas
            if max_abs_z > self.HIGH_CONFIDENCE_ZSCORE:
                synthetic_score = max(synthetic_score, 0.75)
            elif max_abs_z > self.ANOMALY_THRESHOLD_ZSCORE:
                synthetic_score = max(synthetic_score, 0.5)
            
            # Calcular confianza basada en consistencia entre capas
            z_std = np.std(z_scores)
            if z_std < 1.0:
                confidence = 0.9  # Muy consistente
            elif z_std < 2.0:
                confidence = 0.7
            else:
                confidence = 0.5  # Alta variabilidad, menor confianza
            
            # Agregar evidencia resumida
            anomalous_layers = sum(1 for z in z_scores if abs(z) > self.ANOMALY_THRESHOLD_ZSCORE)
            if anomalous_layers > 0:
                evidence.insert(0, f"‚ö†Ô∏è {anomalous_layers}/{len(z_scores)} capas con LID an√≥malo")
            else:
                evidence.insert(0, "‚úÖ Estructura dimensional dentro de par√°metros normales")
            
            # Guardar datos crudos
            raw_data["summary"] = {
                "avg_z_score": float(avg_z),
                "max_abs_z_score": float(max_abs_z),
                "z_std": float(z_std),
                "anomalous_layers": anomalous_layers
            }
            
            result = ExpertResult(
                name="multiLID",
                score=float(np.clip(synthetic_score, 0.0, 1.0)),
                confidence=float(confidence),
                evidence=evidence,
                raw_data=raw_data
            )
            
            logger.info(f"‚úÖ multiLID completado: score={result.score:.2f}, confianza={result.confidence:.2f}")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Error en an√°lisis multiLID: {e}")
            return ExpertResult(
                name="multiLID",
                score=0.5,  # Score neutro en error
                confidence=0.1,  # Baja confianza
                evidence=[f"‚ö†Ô∏è Error en an√°lisis: {str(e)}"],
                raw_data={"error": str(e)}
            )
