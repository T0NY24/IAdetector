# üïµÔ∏è‚Äç‚ôÄÔ∏è UIDE Forense AI

<div align="center">

![Python](https://img.shields.io/badge/Python-3.9+-3776AB?style=for-the-badge&logo=python&logoColor=white)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)
![HuggingFace](https://img.shields.io/badge/ü§ó_Hugging_Face-Models-FFD21E?style=for-the-badge)
![License](https://img.shields.io/badge/License-Academic-00ADD8?style=for-the-badge)

### Sistema Multimodal de Detecci√≥n de Deepfakes y Contenido Sint√©tico

**Plataforma basada en Inteligencia Artificial y Arquitectura Modular para an√°lisis forense de Imagen, Video y Audio**

---

[üìã Caracter√≠sticas](#-caracter√≠sticas-principales) ‚Ä¢ [‚öôÔ∏è Instalaci√≥n](#Ô∏è-instalaci√≥n) ‚Ä¢ [üöÄ Uso](#-gu√≠a-de-uso) ‚Ä¢ [üèóÔ∏è Arquitectura](#Ô∏è-arquitectura-del-sistema) ‚Ä¢ [üìö Documentaci√≥n](#-documentaci√≥n-t√©cnica)

</div>

---

## üìã Caracter√≠sticas Principales

### üñºÔ∏è **An√°lisis Forense de Im√°genes**
Sistema de detecci√≥n h√≠brida basado en ensamble de modelos especializados:

- **Motor de Detecci√≥n GAN**: An√°lisis de artefactos generados por StyleGAN, ProGAN y FaceApp mediante arquitectura ResNet50
- **Motor de Detecci√≥n por Difusi√≥n**: Identificaci√≥n de contenido generado por Stable Diffusion, DALL-E 3 y Midjourney usando Vision Transformers (ViT)
- **Sistema de Ensamble Inteligente**: Combinaci√≥n ponderada de ambos motores para m√°xima precisi√≥n y cobertura
- **Reportes Detallados**: Identificaci√≥n del origen probable y visualizaci√≥n de mapas de calor de manipulaci√≥n

### üîä **Detecci√≥n de Audio Sint√©tico**
An√°lisis espectral avanzado para identificar voces artificiales:

- Detecci√≥n de voces clonadas generadas por ElevenLabs, RVC, Coqui TTS y similares
- An√°lisis de caracter√≠sticas espectrales mediante procesamiento con Librosa
- Clasificaci√≥n binaria: Audio Humano vs Audio Sint√©tico
- Generaci√≥n de espectrogramas Mel para visualizaci√≥n de anomal√≠as
- Soporte para m√∫ltiples formatos: WAV, MP3, FLAC, OGG

### üé• **Detecci√≥n de Deepfakes en Video**
Sistema de an√°lisis temporal para manipulaciones faciales:

- An√°lisis frame-por-frame mediante arquitectura XceptionNet
- Detecci√≥n de Face Swap y reenactment facial
- Extracci√≥n y seguimiento de rostros mediante MTCNN
- Muestreo inteligente optimizado para rendimiento
- Generaci√≥n de gr√°ficos de confianza temporal

### üé® **Arquitectura y Experiencia de Usuario**
Dise√±o modular profesional con interfaz intuitiva:

- **Clean Architecture**: Separaci√≥n de responsabilidades (Core, Modules, Utils)
- **Gesti√≥n Eficiente de Recursos**: Carga diferida (Lazy Loading) de modelos
- **Interfaz Gradio Interactiva**: Reportes visuales en tiempo real
- **Sistema de Logs**: Trazabilidad completa de operaciones
- **Manejo Robusto de Errores**: Validaciones y recuperaci√≥n autom√°tica

---

## üíª Requisitos del Sistema

### Requisitos de Hardware

| Componente | M√≠nimo | Recomendado | √ìptimo |
|------------|--------|-------------|--------|
| **RAM** | 8 GB | 16 GB | 32 GB |
| **CPU** | Intel i5 / Ryzen 5 | Intel i7 / Ryzen 7 | Intel i9 / Ryzen 9 |
| **GPU** | Integrada | NVIDIA GTX 1060 (6GB) | NVIDIA RTX 3060+ |
| **Almacenamiento** | 5 GB libres | 10 GB libres | SSD con 20 GB |
| **Conexi√≥n** | Internet (primera ejecuci√≥n) | Banda ancha | - |

### Requisitos de Software

- **Sistema Operativo**: Windows 10/11, Linux (Ubuntu 20.04+), macOS 10.15+
- **Python**: Versi√≥n 3.9, 3.10 o 3.11 (recomendado 3.10)
- **FFmpeg**: Requerido para procesamiento de audio/video
  - Windows: Descargar desde [ffmpeg.org](https://ffmpeg.org) y agregar al PATH
  - Linux: `sudo apt install ffmpeg`
  - macOS: `brew install ffmpeg`

---

## ‚öôÔ∏è Instalaci√≥n

### Paso 1: Clonar el Repositorio

```bash
git clone https://github.com/T0NY24/ProyectoForenseUIDE.git
cd ProyectoForenseUIDE
```

### Paso 2: Crear Entorno Virtual

**Windows:**
```bash
py -m venv venv
venv\Scripts\activate
```

**Linux / macOS:**
```bash
python3 -m venv venv
source venv/bin/activate
```

### Paso 3: Instalar Dependencias

```bash
py -m pip install -r requirements.txt
```

> **Nota**: La instalaci√≥n puede tardar varios minutos dependiendo de la velocidad de conexi√≥n. Se descargar√°n aproximadamente 2-3 GB de dependencias.

### Paso 4: Verificar Instalaci√≥n de FFmpeg

```bash
ffmpeg -version
```

Si el comando no es reconocido, consulte la [gu√≠a de instalaci√≥n de FFmpeg](https://ffmpeg.org/download.html).

### Paso 5: Configuraci√≥n de Modelos

Los modelos de Hugging Face se descargar√°n autom√°ticamente en la primera ejecuci√≥n. Aseg√∫rese de tener:

- Conexi√≥n a internet estable
- Espacio suficiente en disco (~2 GB adicionales)
- El archivo `blur_jpg_prob0.1.pth` en la carpeta `weights/`

---

## üöÄ Gu√≠a de Uso

### Iniciar la Aplicaci√≥n

```bash
py app.py
```

**Primera ejecuci√≥n:**
- El sistema descargar√° los modelos necesarios (~1-2 GB)
- Este proceso puede tardar 5-10 minutos
- Los modelos se almacenan en cach√© para ejecuciones futuras

**Acceso a la interfaz:**

La aplicaci√≥n se abrir√° autom√°ticamente en tu navegador en:
```
http://localhost:7860
```

Si no se abre autom√°ticamente, copia y pega la URL en tu navegador.

---

### üì∏ M√≥dulo de An√°lisis de Im√°genes

**Proceso de an√°lisis:**

1. **Cargar imagen**: Haz clic en "Upload" o arrastra una imagen (JPG, PNG, WebP)
2. **Ejecutar an√°lisis**: El sistema procesar√° la imagen con ambos motores
3. **Revisar resultados**:
   - Probabilidad de manipulaci√≥n (0-100%)
   - T√©cnica de generaci√≥n detectada (GAN vs Difusi√≥n)
   - Visualizaci√≥n de √°reas sospechosas
   - Origen probable (StyleGAN, Midjourney, etc.)

**Formatos soportados**: JPG, JPEG, PNG, WebP, BMP  
**Tama√±o m√°ximo**: 10 MB  
**Resoluci√≥n recomendada**: 512x512 a 2048x2048 p√≠xeles

---

### üéµ M√≥dulo de An√°lisis de Audio

**Opciones de entrada:**

1. **Subir archivo**: Arrastra o selecciona un archivo de audio
2. **Grabar en vivo**: Usa el micr√≥fono para grabar directamente

**Proceso de an√°lisis:**

1. Haz clic en **"Analizar Audio"**
2. El sistema generar√°:
   - Espectrograma Mel del audio
   - Clasificaci√≥n (Humano / Sint√©tico)
   - Nivel de confianza (0-100%)
   - Caracter√≠sticas espectrales detectadas

**Formatos soportados**: WAV, MP3, FLAC, OGG, M4A  
**Duraci√≥n m√°xima**: 60 segundos (recomendado: 10-30 segundos)  
**Calidad recomendada**: 16-bit, 44.1 kHz o superior

---

### üé¨ M√≥dulo de An√°lisis de Video

**Proceso de an√°lisis:**

1. **Cargar video**: Sube un archivo de video (MP4, AVI, MOV)
2. **Configurar par√°metros** (opcional):
   - Frames a analizar
   - Umbral de detecci√≥n
3. **Ejecutar an√°lisis**: El sistema procesar√° el video frame por frame
4. **Revisar resultados**:
   - Gr√°fico de confianza temporal
   - Frames sospechosos identificados
   - Porcentaje de frames manipulados

**Formatos soportados**: MP4, AVI, MOV, MKV  
**Duraci√≥n m√°xima**: 5 minutos  
**Resoluci√≥n recomendada**: 720p o superior

---

## üèóÔ∏è Arquitectura del Sistema

### Estructura de Directorios

```
ProyectoForenseUIDE/
‚îÇ
‚îú‚îÄ‚îÄ üìÅ core/                      # N√∫cleo del sistema
‚îÇ   ‚îú‚îÄ‚îÄ model_manager.py          # Gestor centralizado de modelos (Singleton)
‚îÇ   ‚îî‚îÄ‚îÄ processor.py              # Pipelines de preprocesamiento
‚îÇ
‚îú‚îÄ‚îÄ üìÅ modules/                   # M√≥dulos de detecci√≥n independientes
‚îÇ   ‚îú‚îÄ‚îÄ image_forensics.py        # Ensamble GAN + Difusi√≥n
‚îÇ   ‚îú‚îÄ‚îÄ audio_forensics.py        # Detector de audio sint√©tico
‚îÇ   ‚îî‚îÄ‚îÄ video_forensics.py        # Detector de deepfakes XceptionNet
‚îÇ
‚îú‚îÄ‚îÄ üìÅ utils/                     # Utilidades transversales
‚îÇ   ‚îú‚îÄ‚îÄ file_handlers.py          # Validaci√≥n y manejo de archivos
‚îÇ   ‚îú‚îÄ‚îÄ plotting.py               # Generaci√≥n de visualizaciones
‚îÇ   ‚îî‚îÄ‚îÄ logger.py                 # Sistema de logging
‚îÇ
‚îú‚îÄ‚îÄ üìÅ weights/                   # Pesos de modelos locales
‚îÇ   ‚îî‚îÄ‚îÄ blur_jpg_prob0.1.pth      # Modelo GAN ResNet50
‚îÇ
‚îú‚îÄ‚îÄ üìÅ cache/                     # Cach√© de modelos HuggingFace
‚îú‚îÄ‚îÄ üìÅ temp/                      # Archivos temporales
‚îÇ
‚îú‚îÄ‚îÄ üìÑ app.py                     # Interfaz Gradio (Capa de presentaci√≥n)
‚îú‚îÄ‚îÄ üìÑ config.py                  # Configuraci√≥n global del sistema
‚îú‚îÄ‚îÄ üìÑ requirements.txt           # Dependencias Python
‚îî‚îÄ‚îÄ üìÑ README.md                  # Este archivo
```

### Flujo de Procesamiento

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    INPUT DEL USUARIO                        ‚îÇ
‚îÇ              (Imagen / Audio / Video)                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  ROUTER DE TIPO                             ‚îÇ
‚îÇ            (Detector autom√°tico de formato)                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ                 ‚îÇ                 ‚îÇ
       ‚ñº                 ‚ñº                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   IMAGEN    ‚îÇ   ‚îÇ    AUDIO    ‚îÇ   ‚îÇ    VIDEO    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ                 ‚îÇ                 ‚îÇ
       ‚ñº                 ‚ñº                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Motor GAN   ‚îÇ   ‚îÇ  Librosa    ‚îÇ   ‚îÇ   MTCNN     ‚îÇ
‚îÇ (ResNet50)  ‚îÇ   ‚îÇ Extracci√≥n  ‚îÇ   ‚îÇ  Extracci√≥n ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ Espectral   ‚îÇ   ‚îÇ  de Rostros ‚îÇ
       ‚îÇ          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ                 ‚îÇ                 ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚ñº                 ‚ñº
‚îÇ Motor Dif.  ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   (ViT)     ‚îÇ   ‚îÇ Transformer ‚îÇ   ‚îÇ XceptionNet ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ    Audio    ‚îÇ   ‚îÇ   Frame x   ‚îÇ
       ‚îÇ          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ    Frame    ‚îÇ
       ‚îÇ                 ‚îÇ          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚ñº                 ‚ñº                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  L√≥gica de  ‚îÇ   ‚îÇ Clasificador‚îÇ   ‚îÇ  Agregaci√≥n ‚îÇ
‚îÇ  Ensamble   ‚îÇ   ‚îÇ   Binario   ‚îÇ   ‚îÇ  Temporal   ‚îÇ
‚îÇ    (MAX)    ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ                 ‚îÇ
       ‚îÇ                 ‚îÇ                 ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚îÇ                 ‚îÇ
                ‚ñº                 ‚ñº
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ    GENERACI√ìN DE REPORTES     ‚îÇ
        ‚îÇ  (Visualizaciones + M√©tricas) ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ
                        ‚ñº
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ  OUTPUT USUARIO ‚îÇ
              ‚îÇ  (Interfaz Web) ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Patrones de Dise√±o Implementados

- **Singleton**: Gestor de modelos (evita duplicaci√≥n en memoria)
- **Strategy**: Diferentes estrategias de detecci√≥n por modalidad
- **Factory**: Creaci√≥n din√°mica de procesadores seg√∫n tipo de archivo
- **Observer**: Sistema de logging y eventos
- **Facade**: Interfaz simplificada para operaciones complejas

---

## üìö Documentaci√≥n T√©cnica

### Modelos de IA Utilizados

#### 1Ô∏è‚É£ **Detecci√≥n de Im√°genes: Estrategia de Ensamble**

**Motor GAN (Generaci√≥n Antigua)**
- **Arquitectura**: CNNDetection basada en ResNet50
- **Especialidad**: StyleGAN, ProGAN, FaceApp
- **T√©cnica**: An√°lisis de patrones de tablero de ajedrez
- **Referencia**: Wang et al. - "CNN-generated images are surprisingly easy to spot... for now"

**Motor Difusi√≥n (Generaci√≥n Moderna)**
- **Arquitectura**: Vision Transformer (ViT-B/16)
- **Especialidad**: Stable Diffusion, DALL-E 3, Midjourney
- **T√©cnica**: Detecci√≥n de ruido latente gaussiano
- **Fine-tuning**: Dataset propietario de 100K im√°genes sint√©ticas

**L√≥gica de Ensamble**
```python
prediccion_final = max(score_gan, score_difusion)
origen = "GAN" if score_gan > score_difusion else "Difusi√≥n"
```

#### 2Ô∏è‚É£ **Detecci√≥n de Audio Sint√©tico**

**Modelo Base**
- **Arquitectura**: Wav2Vec 2.0 / HuBERT
- **Especialidad**: TTS (Text-to-Speech) y Voice Cloning
- **T√©cnica**: An√°lisis de coeficientes MFCC y espectrograma Mel

**Caracter√≠sticas Analizadas**
- Discontinuidades espectrales
- Artefactos de s√≠ntesis en altas frecuencias
- Patrones de pitch antinaturales
- Ausencia de microfon√≠a ambiental

#### 3Ô∏è‚É£ **Detecci√≥n de Deepfakes en Video**

**Modelo Principal**
- **Arquitectura**: XceptionNet (Depthwise Separable Convolutions)
- **Dataset de Entrenamiento**: FaceForensics++ (1.8M frames)
- **M√©todos Detectados**: Face2Face, FaceSwap, NeuralTextures, Deepfakes

**Pipeline de Procesamiento**
1. Extracci√≥n de rostros (MTCNN)
2. Normalizaci√≥n y aumento de datos
3. Inferencia por frame
4. Agregaci√≥n temporal con ventana deslizante

---

## ‚ö†Ô∏è Limitaciones Conocidas

### Limitaciones T√©cnicas

1. **Procesamiento de Audio**
   - El ruido de fondo intenso puede afectar la precisi√≥n
   - M√∫sica de fondo reduce la efectividad del an√°lisis
   - Audios de menos de 3 segundos pueden dar falsos positivos

2. **An√°lisis de Im√°genes**
   - Im√°genes con post-procesamiento intenso (filtros de Instagram) pueden confundir al modelo ViT
   - Compresi√≥n JPEG agresiva puede generar falsos positivos
   - Im√°genes de resoluci√≥n muy baja (<256x256) tienen menor precisi√≥n

3. **Detecci√≥n de Video**
   - Videos con mala iluminaci√≥n reducen la precisi√≥n
   - M√∫ltiples rostros simult√°neos requieren m√°s recursos
   - Videos de m√°s de 5 minutos requieren tiempo considerable de procesamiento

4. **Recursos del Sistema**
   - La primera ejecuci√≥n requiere conexi√≥n a internet
   - El uso simult√°neo de los tres m√≥dulos consume ~12 GB de RAM
   - Sin GPU, el procesamiento puede ser 5-10x m√°s lento

### Limitaciones Metodol√≥gicas

- Los resultados son **probabil√≠sticos**, no determin√≠sticos
- La precisi√≥n var√≠a seg√∫n la calidad del contenido sint√©tico
- Nuevas t√©cnicas de generaci√≥n pueden no ser detectadas hasta actualizaci√≥n del modelo
- No garantiza detecci√≥n de t√©cnicas de evasi√≥n adversarial

---

## ‚öñÔ∏è Consideraciones √âticas y Legales

### Uso Responsable

Esta herramienta ha sido desarrollada exclusivamente con fines **acad√©micos y de investigaci√≥n** como trabajo de titulaci√≥n en Ingenier√≠a en Tecnolog√≠as de la Informaci√≥n.

**IMPORTANTE:**
- ‚ùå Los resultados **NO constituyen prueba pericial legal**
- ‚ùå No debe usarse como √∫nica evidencia en procesos judiciales
- ‚ùå No reemplaza la opini√≥n de peritos forenses certificados
- ‚úÖ Es una herramienta de apoyo para an√°lisis preliminar
- ‚úÖ Puede usarse en contextos educativos y de investigaci√≥n

### Privacidad y Datos

- Los archivos procesados **NO se almacenan** en servidores externos
- Todo el procesamiento ocurre **localmente** en su m√°quina
- No se recopilan datos personales ni estad√≠sticas de uso
- Los archivos temporales se eliminan autom√°ticamente

### Transparencia Algor√≠tmica

Los modelos de IA pueden presentar sesgos inherentes:
- Mejor rendimiento en rostros con buena iluminaci√≥n
- Posible sesgo racial en datasets de entrenamiento
- Mayor precisi√≥n en contenido en ingl√©s/espa√±ol

---




## ü§ù Contribuciones

Este proyecto es de c√≥digo cerrado durante el per√≠odo de evaluaci√≥n acad√©mica. Despu√©s de la sustentaci√≥n, se evaluar√° la posibilidad de liberar el c√≥digo bajo licencia acad√©mica.

### Reporte de Bugs

Si encuentras un error, por favor contacta al equipo de desarrollo con:
- Descripci√≥n detallada del problema
- Pasos para reproducir el error
- Archivos de log (si est√°n disponibles)

---

## üìû Contacto y Soporte

### Equipo de Desarrollo

**Universidad Internacional del Ecuador (UIDE)**  
Facultad de Ingenier√≠a en Tecnolog√≠as de la Informaci√≥n

| Integrante | Rol | Email |
|------------|-----|-------|
| **Anthony P√©rez** |
| **Bruno Ortega** | 
| **Manuel Pacheco** | 


---

## üìñ Referencias Acad√©micas

1. Wang, S. Y., et al. (2020). "CNN-generated images are surprisingly easy to spot... for now." *CVPR 2020*.

2. Rossler, A., et al. (2019). "FaceForensics++: Learning to Detect Manipulated Facial Images." *ICCV 2019*.

3. Chollet, F. (2017). "Xception: Deep Learning with Depthwise Separable Convolutions." *CVPR 2017*.

4. Dosovitskiy, A., et al. (2021). "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale." *ICLR 2021*.

5. Baevski, A., et al. (2020). "wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations." *NeurIPS 2020*.

---

## üìÑ Licencia

**Licencia Acad√©mica**

¬© 2025 Universidad Internacional del Ecuador (UIDE)

---

<div align="center">


</div>