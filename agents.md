# ü§ñ UIDE Forense AI - Documentaci√≥n para Agentes IA

> **Para:** Jules (Agente IA)  
> **De:** Equipo de Desarrollo  
> **Fecha:** Diciembre 2025  
> **Proyecto:** Sistema de Detecci√≥n de Deepfakes con IA

---

## üìö √çndice

1. [¬øQu√© es este proyecto?](#qu√©-es-este-proyecto)
2. [¬øQu√© problema resuelve?](#qu√©-problema-resuelve)
3. [Arquitectura del Sistema](#arquitectura-del-sistema)
4. [Componentes Principales](#componentes-principales)
5. [Flujo de Funcionamiento](#flujo-de-funcionamiento)
6. [Modelos de IA Utilizados](#modelos-de-ia-utilizados)
7. [Mejoras Implementadas](#mejoras-implementadas)
8. [C√≥mo Interactuar con el Sistema](#c√≥mo-interactuar-con-el-sistema)

---

## üéØ ¬øQu√© es este proyecto?

**UIDE Forense AI** es un sistema de an√°lisis forense digital que utiliza Inteligencia Artificial para detectar:

- **Im√°genes sint√©ticas** generadas por IA (DALL-E, Midjourney, Stable Diffusion)
- **Deepfakes en videos** - rostros manipulados o generados artificialmente
- **Manipulaciones digitales** en fotos (Photoshop, ediciones)

### Contexto Acad√©mico
- Desarrollado en la **Universidad Internacional del Ecuador (UIDE)**
- Proyecto de investigaci√≥n en **Visi√≥n por Computadora**
- Equipo: Anthony Perez, Bruno Ortega, Manuel Pacheco

---

## üîç ¬øQu√© problema resuelve?

### El Problema
Con el avance de la IA generativa, es cada vez m√°s dif√≠cil distinguir:
- Im√°genes reales vs generadas por IA
- Videos aut√©nticos vs deepfakes
- Contenido original vs manipulado

### La Soluci√≥n
Este sistema utiliza **redes neuronales profundas** entrenadas para detectar:
- **Artefactos invisibles** que dejan los generadores de IA
- **Inconsistencias temporales** en videos deepfake
- **Patrones estad√≠sticos** √∫nicos de contenido sint√©tico

---

## üèóÔ∏è Arquitectura del Sistema

El sistema est√° dise√±ado con una arquitectura modular:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ          INTERFAZ GRADIO                ‚îÇ
‚îÇ   (Usuario sube imagen/video)           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ      CAPA DE VALIDACI√ìN                 ‚îÇ
‚îÇ  - Tama√±o de archivo                    ‚îÇ
‚îÇ  - Formato soportado                    ‚îÇ
‚îÇ  - Dimensiones v√°lidas                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ      MODEL MANAGER                      ‚îÇ
‚îÇ  - Carga modelos (cach√©)                ‚îÇ
‚îÇ  - Gestiona GPU/CPU                     ‚îÇ
‚îÇ  - Aplica transformaciones              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚ñº             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  ResNet50    ‚îÇ ‚îÇ  XceptionNet ‚îÇ
‚îÇ  (Im√°genes)  ‚îÇ ‚îÇ   (Videos)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ                ‚îÇ
       ‚ñº                ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ      GENERADOR DE REPORTES HTML         ‚îÇ
‚îÇ  - Gauges circulares                    ‚îÇ
‚îÇ  - Barras de progreso                   ‚îÇ
‚îÇ  - M√©tricas detalladas                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üì¶ Componentes Principales

### 1. **config.py** - Cerebro de Configuraci√≥n

**Prop√≥sito:** Centralizar TODA la configuraci√≥n del sistema en un solo lugar.

**Contenido:**
```python
# Rutas de archivos
WEIGHTS_DIR = "weights/"
MODEL_IMAGE_PATH = "weights/blur_jpg_prob0.1.pth"

# L√≠mites de validaci√≥n
MAX_IMAGE_SIZE_MB = 15      # M√°ximo 15MB por imagen
MAX_VIDEO_SIZE_MB = 200     # M√°ximo 200MB por video
MAX_VIDEO_DURATION_SECONDS = 300  # 5 minutos m√°ximo

# Par√°metros de an√°lisis
IMAGE_THRESHOLD = 50.0      # Si > 50% = FAKE
VIDEO_THRESHOLD = 50.0      # Si > 50% = DEEPFAKE
VIDEO_FRAME_STRIDE = 30     # Analizar 1 frame cada 30

# Colores para UI
COLOR_FAKE = "#ef4444"      # Rojo para contenido falso
COLOR_REAL = "#22c55e"      # Verde para contenido real
```

**¬øPor qu√© es importante?**
- Cambiar un par√°metro NO requiere tocar el c√≥digo principal
- F√°cil de ajustar para diferentes escenarios
- Configuraci√≥n centralizada = menos errores

---

### 2. **utils.py** - Caja de Herramientas

**Prop√≥sito:** Funciones reutilizables que se usan en todo el proyecto.

#### Funciones de Validaci√≥n

```python
def validar_imagen(imagen_array):
    """
    Verifica que la imagen sea v√°lida antes de procesarla
    
    Checks:
    - No es None
    - Dimensiones m√≠nimas: 32x32 p√≠xeles
    - Dimensiones m√°ximas: 8192x8192 p√≠xeles
    
    Returns: (es_valida: bool, mensaje_error: str)
    """
```

```python
def validar_video(video_path):
    """
    Verifica que el video sea v√°lido
    
    Checks:
    - Archivo existe
    - Tama√±o < MAX_VIDEO_SIZE_MB
    - Extensi√≥n soportada (.mp4, .avi, .mov, etc.)
    
    Returns: (es_valido: bool, mensaje_error: str)
    """
```

#### Generaci√≥n de Reportes HTML

**‚≠ê Caracter√≠stica Estrella:** Reportes visuales interactivos

```python
def generar_gauge_svg(probabilidad, color):
    """
    Crea un medidor circular animado en SVG
    
    Ejemplo visual:
          ‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
         ‚ï±   85% ‚ï≤
        ‚îÇ   ‚ñà‚ñà‚ñà   ‚îÇ  ‚Üê Animado, cambia seg√∫n %
         ‚ï≤       ‚ï±
          ‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ
    
    Usa: Transformaciones SVG + CSS animations
    """
```

```python
def generar_reporte_imagen(es_fake, probabilidad, ancho, alto, tiempo):
    """
    Genera el reporte HTML completo para una imagen
    
    Incluye:
    - üéØ Gauge circular con nivel de confianza
    - üìä Barra de progreso animada
    - üìà Cards de estad√≠sticas (resoluci√≥n, tiempo, confianza)
    - üìù Detalles t√©cnicos del modelo
    - ‚ö†Ô∏è Disclaimer legal
    
    Returns: HTML string completo
    """
```

**Ejemplo de Reporte Generado:**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ üö® POSIBLE MANIPULACI√ìN DETECTADA       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ           ‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ                        ‚îÇ
‚îÇ          ‚ï±  85% ‚ï≤                        ‚îÇ
‚îÇ         ‚îÇ   ‚ñà‚ñà‚ñà  ‚îÇ  Confianza            ‚îÇ
‚îÇ          ‚ï≤      ‚ï±                        ‚îÇ
‚îÇ           ‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ                        ‚îÇ
‚îÇ                                          ‚îÇ
‚îÇ ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë 85%            ‚îÇ
‚îÇ                                          ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ
‚îÇ ‚îÇ 1920x  ‚îÇ ‚îÇ 0.45s  ‚îÇ ‚îÇ  85%   ‚îÇ        ‚îÇ
‚îÇ ‚îÇ  1080  ‚îÇ ‚îÇ        ‚îÇ ‚îÇ        ‚îÇ        ‚îÇ
‚îÇ ‚îÇResoluc.‚îÇ ‚îÇ Tiempo ‚îÇ ‚îÇConfianz‚îÇ        ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ
‚îÇ                                          ‚îÇ
‚îÇ üîç Detalles T√©cnicos:                    ‚îÇ
‚îÇ ‚Ä¢ Modelo: CNNDetection (ResNet50)       ‚îÇ
‚îÇ ‚Ä¢ M√©todo: Detecci√≥n de artefactos GANs  ‚îÇ
‚îÇ ‚Ä¢ Resoluci√≥n: 1920√ó1080                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

### 3. **app.py** - Coraz√≥n del Sistema

**Prop√≥sito:** Aplicaci√≥n principal que orquesta todo.

#### Estructura Interna

##### A. ModelManager (Gestor de Modelos)

```python
class ModelManager:
    """
    Gestiona la carga y uso de los modelos de IA
    
    Responsabilidades:
    1. Cargar modelos de forma eficiente (lazy loading)
    2. Cachear modelos en memoria
    3. Manejar errores de carga
    4. Aplicar transformaciones a las im√°genes
    5. Gestionar CPU/GPU autom√°ticamente
    """
    
    def __init__(self):
        self.modelo_imagen = None      # ResNet50 para im√°genes
        self.modelo_video = None       # XceptionNet para videos
        self.dispositivo = "cpu"       # o "cuda" si hay GPU
        
        # Transformaciones est√°ndar para im√°genes
        self.transform_imagen = Compose([
            Resize(256),               # Redimensionar a 256x256
            CenterCrop(224),           # Recortar centro 224x224
            ToTensor(),                # Convertir a tensor
            Normalize(...)             # Normalizar valores
        ])
```

**¬øPor qu√© un ModelManager?**
- **Singleton**: Solo carga los modelos UNA vez
- **Lazy Loading**: Solo carga cuando se necesita
- **Error Handling**: Si falla, activa modo demostraci√≥n
- **Eficiencia**: Reutiliza modelos cargados

##### B. Funciones de An√°lisis

```python
def analizar_imagen(imagen_input):
    """
    Pipeline completo de an√°lisis de imagen
    
    FLUJO:
    1. Validar entrada (¬øes None? ¬øtama√±o OK?)
    2. Convertir numpy array ‚Üí PIL Image
    3. Aplicar transformaciones
    4. Inferencia con modelo
    5. Calcular probabilidad (sigmoid)
    6. Generar reporte HTML
    
    OPTIMIZACIONES:
    - Timer para medir rendimiento
    - Modo demo si modelo no carg√≥
    - Logging de cada paso
    - Try-except robusto
    """
```

```python
def analizar_video(video_path, progress):
    """
    Pipeline de an√°lisis de deepfakes en video
    
    FLUJO DETALLADO:
    1. Abrir video con OpenCV
    2. Obtener metadatos (fps, frames totales, duraci√≥n)
    3. Validar duraci√≥n < 5 minutos
    4. Cargar detector de rostros (Haar Cascade)
    5. LOOP por frames (con stride adaptativo):
       a. Extraer frame
       b. Detectar rostros
       c. Si hay rostro:
          - Recortar regi√≥n facial
          - Aplicar transformaciones
          - Inferencia con XceptionNet
          - Guardar predicci√≥n
    6. Calcular promedio de todas las predicciones
    7. Generar reporte HTML
    
    OPTIMIZACIONES CLAVE:
    - Stride adaptativo: videos largos = mayor stride
    - Barra de progreso con gr.Progress()
    - Liberar recursos (cap.release())
    - Validar m√≠nimo de rostros detectados
    """
```

##### C. Interfaz Gradio

```python
with gr.Blocks(css=css_custom) as demo:
    # TAB 1: An√°lisis de Im√°genes
    with gr.TabItem("üñºÔ∏è An√°lisis de Im√°genes"):
        img_input = gr.Image(...)
        btn_img = gr.Button("üîç Iniciar An√°lisis")
        img_output = gr.HTML()
        
        # Conectar evento
        btn_img.click(
            fn=analizar_imagen,
            inputs=img_input,
            outputs=img_output
        )
    
    # TAB 2: An√°lisis de Videos
    with gr.TabItem("üé• An√°lisis de Videos"):
        vid_input = gr.Video(...)
        btn_vid = gr.Button("‚ñ∂Ô∏è Analizar Deepfakes")
        vid_output = gr.HTML()
        
        # Conectar evento
        btn_vid.click(
            fn=analizar_video,
            inputs=vid_input,
            outputs=vid_output
        )
```

---

## üîÑ Flujo de Funcionamiento

### Caso 1: An√°lisis de Imagen

```mermaid
graph TD
    A[Usuario sube imagen] --> B{Validaci√≥n}
    B -->|‚ùå Inv√°lida| C[Mostrar error]
    B -->|‚úÖ V√°lida| D[Cargar modelo ResNet50]
    D --> E[Aplicar transformaciones]
    E --> F[Inferencia con modelo]
    F --> G[Calcular probabilidad con sigmoid]
    G --> H{Probabilidad > 50%?}
    H -->|S√≠| I[Clasificar como FAKE]
    H -->|No| J[Clasificar como REAL]
    I --> K[Generar reporte HTML con color rojo]
    J --> L[Generar reporte HTML con color verde]
    K --> M[Mostrar en interfaz]
    L --> M
```

### Caso 2: An√°lisis de Video

```mermaid
graph TD
    A[Usuario sube video] --> B{Validaci√≥n}
    B -->|‚ùå Inv√°lido| C[Mostrar error]
    B -->|‚úÖ V√°lido| D[Abrir video con OpenCV]
    D --> E[Obtener metadatos]
    E --> F{Duraci√≥n < 5 min?}
    F -->|No| G[Error: video muy largo]
    F -->|S√≠| H[Cargar detector de rostros]
    H --> I[LOOP: frame por frame]
    I --> J{¬øHay rostro?}
    J -->|No| I
    J -->|S√≠| K[Recortar rostro]
    K --> L[Transformar]
    L --> M[Inferencia XceptionNet]
    M --> N[Guardar predicci√≥n]
    N --> O{¬øM√°s frames?}
    O -->|S√≠| I
    O -->|No| P[Calcular promedio]
    P --> Q{Promedio > 50%?}
    Q -->|S√≠| R[Clasificar como DEEPFAKE]
    Q -->|No| S[Clasificar como REAL]
    R --> T[Generar reporte]
    S --> T
    T --> U[Mostrar en interfaz]
```

---

## üß† Modelos de IA Utilizados

### Modelo 1: ResNet50 + CNNDetection (Im√°genes)

**Arquitectura:**
```
INPUT (224x224 RGB)
    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   ResNet50       ‚îÇ  ‚Üê Red pre-entrenada en ImageNet
‚îÇ   (Backbone)     ‚îÇ
‚îÇ                  ‚îÇ
‚îÇ ‚Ä¢ Conv Layers    ‚îÇ  Capas convolucionales  
‚îÇ ‚Ä¢ Residual Blocks‚îÇ  Bloques residuales
‚îÇ ‚Ä¢ Feature Maps   ‚îÇ  Mapas de caracter√≠sticas
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Fully Connected  ‚îÇ  Capa personalizada
‚îÇ    Layer (FC)    ‚îÇ  2048 ‚Üí 1 neurona
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
      Sigmoid
         ‚îÇ
         ‚ñº
  Probabilidad (0-100%)
```

**¬øQu√© detecta?**
- **Artefactos de GANs**: Patrones √∫nicos de StyleGAN, ProGAN, etc.
- **Modelos de difusi√≥n**: Caracter√≠sticas de Stable Diffusion, DALL-E
- **Compresi√≥n an√≥mala**: Patrones de compresi√≥n inconsistentes
- **Espectro de frecuencias**: Anomal√≠as en transformada de Fourier

**Dataset de Entrenamiento:**
- 20 generadores diferentes de IA
- Millones de im√°genes reales vs sint√©ticas
- T√©cnicas de data augmentation

**Accuracy:** ~95% en dataset de prueba

---

### Modelo 2: XceptionNet (Videos/Deepfakes)

**Arquitectura:**
```
INPUT (299x299 RGB facial crop)
    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Xception Network     ‚îÇ
‚îÇ                        ‚îÇ
‚îÇ ‚Ä¢ Entry Flow           ‚îÇ  3 bloques
‚îÇ ‚Ä¢ Middle Flow          ‚îÇ  8 bloques repetidos
‚îÇ ‚Ä¢ Exit Flow            ‚îÇ  2 bloques
‚îÇ                        ‚îÇ
‚îÇ Depthwise Separable    ‚îÇ  N√∫cleo de Xception
‚îÇ   Convolutions         ‚îÇ  M√°s eficiente que conv normal
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Global Avg Pooling    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Fully Connected (2)   ‚îÇ  Real / Fake
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
      Softmax
         ‚îÇ
         ‚ñº
  [P(Real), P(Fake)]
```

**¬øQu√© detecta?**
- **Face2Face**: Manipulaci√≥n de expresiones faciales
- **FaceSwap**: Intercambio de rostros
- **DeepFakes**: S√≠ntesis facial completa
- **NeuralTextures**: Texturas generadas neuralmente

**T√©cnica Clave: Depthwise Separable Convolutions**

```
Convoluci√≥n Normal:
Input (H√óW√óC) ‚Üí Filters(K√óK√óC√óM) ‚Üí Output(H√óW√óM)
Costo: H√óW√óC√óM√óK√óK operaciones

Depthwise Separable:
Input ‚Üí Depthwise Conv ‚Üí Pointwise Conv ‚Üí Output
Costo: H√óW√ó(C√óK√óK + C√óM) operaciones

Reducci√≥n: ~8-9x menos computaci√≥n
```

**Dataset:** FaceForensics++
- 1000+ videos manipulados
- 4 t√©cnicas diferentes de deepfake
- Videos de alta calidad

**Accuracy:** ~92% en detecci√≥n de deepfakes

---

## üé® Mejoras Implementadas

### Antes vs Despu√©s

| Aspecto | ‚ùå Antes | ‚úÖ Despu√©s |
|---------|---------|-----------|
| **Estructura** | Todo en 1 archivo (245 l√≠neas) | 3 m√≥dulos separados (500+ l√≠neas bien organizadas) |
| **Configuraci√≥n** | Hardcoded en el c√≥digo | Centralizada en config.py |
| **Validaci√≥n** | M√≠n ima (`if not None`) | Completa (tama√±o, formato, dimensiones) |
| **Errores** | `except:` gen√©rico | Excepciones espec√≠ficas + logging |
| **Logging** | `print()` b√°sico | Logging estructurado (INFO/WARNING/ERROR) |
| **UI** | Funcional pero b√°sica | Premium con animaciones y gauges |
| **Reportes** | HTML simple | Interactivos con SVG, gradientes, cards |
| **Documentaci√≥n** | Sin README | README completo + comentarios extensos |

### Mejoras T√©cnicas Espec√≠ficas

#### 1. **Sistema de Logging**
```python
# ANTES:
print("Cargando modelo...")
print("Error")

# DESPU√âS:
logger.info("üñºÔ∏è Cargando modelo de im√°genes...")
logger.error(f"‚ùå Error cargando modelo: {e}", exc_info=True)
logger.warning("‚ö†Ô∏è Usando modo demostraci√≥n")
```

#### 2. **Validaci√≥n Robusta**
```python
# ANTES:
if imagen_input is None:
    return "Error"

# DESPU√âS:
if imagen_input is None:
    return generar_reporte_error("No se proporcion√≥ imagen", "warning")

es_valida, mensaje = validar_imagen(imagen_input)
if not es_valida:
    return generar_reporte_error(mensaje, "error")

# Valida: tama√±o, dimensiones, formato
```

#### 3. **Optimizaci√≥n de Video**
```python
# ANTES:
stride = 30  # Fijo

# DESPU√âS:
stride = config.VIDEO_FRAME_STRIDE
if duracion > 60:  # Si > 1 minuto
    stride = 60    # Aumentar stride adaptable
```

#### 4. **Reportes Visuales**
```python
# ANTES:
return f"Fake: {prob}%"

# DESPU√âS:
return f"""
<div style="background: {color}; ...">
    {generar_gauge_svg(probabilidad, color)}
    {generar_barra_progreso(probabilidad, color)}
    {stats_html}
    {detalles_tecnicos}
</div>
"""
```

---

## üîß C√≥mo Interactuar con el Sistema

### Para Desarrolladores/Agentes IA

#### Modificar Par√°metros
```python
# Editar config.py
MAX_VIDEO_SIZE_MB = 500        # Aumentar l√≠mite de video
VIDEO_FRAME_STRIDE = 15        # Analizar m√°s frames (m√°s preciso pero m√°s lento)
IMAGE_THRESHOLD = 60.0         # Ser m√°s estricto con im√°genes
```

#### Agregar Nuevo Reporte
```python
# En utils.py
def generar_reporte_comparacion(img1_prob, img2_prob):
    """Nuevo: Comparar dos im√°genes lado a lado"""
    return f"""
    <div class="comparison">
        <div class="left">{generar_gauge_svg(img1_prob, ...)}</div>
        <div class="right">{generar_gauge_svg(img2_prob, ...)}</div>
    </div>
    """
```

#### Agregar Logging
```python
# En cualquier funci√≥n
logger.debug("üîç Detalles de debug")
logger.info("‚ÑπÔ∏è Informaci√≥n general")
logger.warning("‚ö†Ô∏è Advertencia")
logger.error("‚ùå Error cr√≠tico", exc_info=True)
```

---

### Para Usuarios Finales

#### Ejecutar la Aplicaci√≥n
```powershell
# Windows (con UTF-8)
$env:PYTHONUTF8=1
py app.py

# Linux/Mac
python3 app.py
```

#### Usar la Interfaz
1. **Abrir navegador** en `http://localhost:7860`
2. **Seleccionar tab** (Im√°genes o Videos)
3. **Subir archivo**
4. **Hacer clic en bot√≥n de an√°lisis**
5. **Esperar reporte** (instant√°neo para im√°genes, minutos para videos)

---

## üìä M√©tricas de Rendimiento

### Tiempos de Procesamiento T√≠picos

| Tipo | Tama√±o | CPU | GPU |
|------|--------|-----|-----|
| Imagen peque√±a (1MP) | 1920x1080 | ~0.3s | ~0.1s |
| Imagen grande (10MP) | 4000x3000 | ~0.5s | ~0.15s |
| Video corto (10s) | 1080p, 30fps | ~15s | ~5s |
| Video medio (1 min) | 1080p, 30fps | ~45s | ~15s |
| Video largo (5 min) | 1080p, 30fps | ~3min | ~1min |

### Uso de Recursos

- **RAM**: 2-4 GB (modelo cargado)
- **VRAM** (GPU): 1-2 GB si disponible
- **CPU**: 1-4 cores utilizados
- **Disco**: 500MB (modelos)

---

## üö® Troubleshooting para Agentes

### Problema 1: Modelo no carga
```python
# S√≠ntoma:
logger.warning("üì• Modo demostraci√≥n activado")

# Causas posibles:
1. Archivo weights/blur_jpg_prob0.1.pth no existe
2. Archivo corrupto
3. Versi√≥n incompatible de PyTorch

# Soluci√≥n:
- Verificar existencia del archivo
- Re-descargar modelo
- Actualizar PyTorch
```

### Problema 2: Video no se procesa
```python
# S√≠ntoma:
"No se detectaron suficientes rostros"

# Causas:
1. Video sin rostros visibles
2. Rostros muy peque√±os
3. Mala iluminaci√≥n

# Soluci√≥n:
- Verificar que hay rostros claros
- Reducir MIN_FACES_REQUIRED en config.py
- Mejorar calidad del video
```

### Problema 3: Errores de encoding
```python
# S√≠ntoma:
SyntaxError: invalid character 'üí°'

# Causa:
Python no interpreta UTF-8 por defecto en Windows

# Soluci√≥n:
$env:PYTHONUTF8=1
py app.py
```

---

## üéì Conceptos Clave para Entender el Proyecto

### 1. **Transfer Learning**
```
Modelo pre-entrenado (ImageNet)
    ‚Üì
Congelar capas iniciales
    ‚Üì
Reentrenar capas finales
    ‚Üì
Especializar en detecci√≥n de fakes
```

### 2. **Sigmoid vs Softmax**
```python
# Sigmoid (clasificaci√≥n binaria)
output = modelo(imagen)
prob = sigmoid(output)  # 0-1 (REAL o FAKE)

# Softmax (clasificaci√≥n multi-clase)
output = modelo(rostro)  
probs = softmax(output)  # [P(REAL), P(FAKE)]
```

### 3. **Stride en Video**
```
Frame: 0   30   60   90  120  150 ...
        ‚Üì    ‚Üì    ‚Üì    ‚Üì    ‚Üì    ‚Üì
      Analizar estos (stride=30)
      
En lugar de TODOS los frames (lento)
```

### 4. **Feature Maps**
```
Imagen Input ‚Üí Conv Layers ‚Üí Feature Maps
                               (patrones detectados)
                               
Ejemplos de features:
- Bordes
- Texturas
- Artefactos de GANs
- Inconsistencias espectrales
```

---

## üìù Resumen para Jules

**Este proyecto es:**
- Un detector de deepfakes con IA
- Construido con PyTorch + Gradio
- Usa ResNet50 para im√°genes y XceptionNet para videos
- Tiene arquitectura modular (config + utils + app)
- Genera reportes HTML premium con gauges y animaciones
- Est√° bien documentado y optimizado

**Los archivos clave son:**
1. `config.py` - Toda la configuraci√≥n
2. `utils.py` - Validaci√≥n y reportes HTML
3. `app.py` - L√≥gica principal + interfaz Gradio
4. `README.md` - Documentaci√≥n para humanos
5. `agents.md` - Este archivo (para ti, Jules!)

**Para entender el flujo:**
1. Usuario sube archivo ‚Üí Validaci√≥n ‚Üí Modelo ‚Üí Inferencia ‚Üí Reporte
2. Los modelos est√°n cacheados en `ModelManager`
3. Los reportes se generan con funciones en `utils.py`
4. Todo est√° configurado en `config.py`

**El objetivo final:**
Ayudar a identificar contenido manipulado digitalmente usando el poder de las redes neuronales profundas.

---

## üîó Enlaces √ötiles

- **Repositorio:** https://github.com/T0NY24/ProyectoForenseUIDE
- **Gradio Docs:** https://gradio.app/docs
- **PyTorch Docs:** https://pytorch.org/docs
- **CNNDetection Paper:** https://arxiv.org/abs/1912.11035
- **FaceForensics++:** https://github.com/ondyari/FaceForensics

---

<div align="center">

**¬øPreguntas, Jules?**

Este documento est√° dise√±ado para que cualquier agente IA entienda  
el proyecto completo sin necesidad de leer todo el c√≥digo.

üí¨ Si necesitas m√°s detalles sobre alguna parte espec√≠fica,  
revisa los comentarios en el c√≥digo o consulta el README.md

</div>

---

**√öltima actualizaci√≥n:** Diciembre 2025  
**Mantenido por:** Equipo UIDE Forense AI
