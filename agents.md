# ü§ñ UIDE Forense AI 15.0 - Documentaci√≥n para Agentes IA

> **Para:** Agentes IA (Claude, Jules, Gemini, etc.)
> **Versi√≥n:** 15.0 (Trinity Judgment: Full React + Flask Migration)
> **Fecha:** Febrero 2026

---

## üìã Resumen del Sistema

Sistema de an√°lisis forense digital avanzado con arquitectura modular **Clean Architecture**. Completamente migrado de Gradio a una arquitectura moderna **React + Flask** con soporte para:

- ‚úÖ **Im√°genes** (multiLID + UFD + Semantic Expert con DeepSeek-R1)
- ‚úÖ **Videos** (XceptionNet - Deepfake facial detection)  
- ‚úÖ **Audio** (HuggingFace AST - Synthetic voice detection)

### M√≥dulos Principales
1. **Image Forensics (V12.0 Trinity Judgment)**:
   - **Peritos (Expert Collectors)**:
     - **multiLID**: An√°lisis de Dimensi√≥n Intr√≠nseca Local (geometr√≠a).
     - **UFD**: Universal Fake Detect (clasificador visual en espacio CLIP).
     - **FFT**: Frequency analysis (detecci√≥n de patrones frecuenciales).
   - **Doctor (Judge)**: **DeepSeek-R1** lee n√∫meros t√©cnicos + descripci√≥n BLIP ‚Üí score.
   - **Sentencia (Verdict)**: Fusion Engine V10.0 (decisi√≥n binaria: threshold 0.60).
2. **Video Forensics**: XceptionNet (an√°lisis frame a frame de rostros).
3. **Audio Forensics**: HuggingFace AST (detecci√≥n de ElevenLabs, RVC, TTS).

---

## üèóÔ∏è Arquitectura del Sistema

El sistema sigue una arquitectura cliente-servidor completamente desacoplada.

```
[React Frontend :5173]
        ‚Üì (HTTP REST API)
[Flask Backend :5000]
  ‚îÇ
  ‚îú‚îÄ‚îÄ‚îÄ /api/analyze_image  ‚Üí ForensicsPipeline (Image)
  ‚îÇ     ‚îú‚îÄ 1. CLIP Feature Extractor (ViT-L/14)
  ‚îÇ     ‚îÇ    ‚îî‚îÄ Image embeddings + Text probabilities
  ‚îÇ     ‚îú‚îÄ 2. Expert Analysis
  ‚îÇ     ‚îÇ    ‚îú‚îÄ multiLID: Local geometry (0-1 score)
  ‚îÇ     ‚îÇ    ‚îú‚îÄ UFD: Visual artifacts (0-1 score)
  ‚îÇ     ‚îÇ    ‚îî‚îÄ Semantic: DeepSeek-R1 reasoning (0-1 score)
  ‚îÇ     ‚îî‚îÄ 3. Fusion Engine V3.3
  ‚îÇ          ‚îî‚îÄ Weighted combination + Hard thresholds
  ‚îÇ
  ‚îú‚îÄ‚îÄ‚îÄ /api/analyze_video  ‚Üí VideoForensicsDetector
  ‚îÇ     ‚îî‚îÄ 1. Frame Extraction (OpenCV)
  ‚îÇ     ‚îî‚îÄ 2. Face Detection (Haar Cascade)
  ‚îÇ     ‚îî‚îÄ 3. XceptionNet Classification
  ‚îÇ
  ‚îî‚îÄ‚îÄ‚îÄ /api/analyze_audio  ‚Üí AudioForensicsDetector
        ‚îî‚îÄ 1. Audio Loading (librosa)
        ‚îî‚îÄ 2. Spectral Analysis
        ‚îî‚îÄ 3. HuggingFace AST Model
```

### Backend (Flask)
- **Path**: `backend/`
- **Entry Point**: `app.py` (Factory Pattern)
- **API**: RESTful con Blueprints modulares (`routes/`)
  - `analyze.py`: Image analysis ‚Üí `/api/analyze_image`
  - `analyze_video.py`: Video analysis ‚Üí `/api/analyze_video`
  - `analyze_audio.py`: Audio analysis ‚Üí `/api/analyze_audio`
  - `semantic.py`: DeepSeek debugging routes
  - `fusion.py`: Fusion Engine testing routes
- **Core Modules**: `modules/` (image_forensics, video_forensics, audio_forensics)
- **Services**: `forensics_pipeline.py` (orquestrador de imagen), `deepseek_client.py` (LLM)

### Frontend (React + Vite)
- **Path**: `frontend/`
- **Tech Stack**: React 18, Vite, CSS Modules (Dark Theme)
- **Components**:
  - Upload: `UploadImage.jsx`, `UploadVideo.jsx`, `UploadAudio.jsx` (drag-and-drop)
  - Results: `ResultCard.jsx`, `VideoResultCard.jsx`, `AudioResultCard.jsx`
  - UI: `AnalysisProgress.jsx`, `DeepSeekChat.jsx`, `ResultsPanel.jsx`
- **Services**: `api.js` (analyzeImage, analyzeVideo, analyzeAudio)
- **State Management**: React hooks en `App.jsx` (sin Redux)

---

## üìÅ Estructura del Proyecto

```
ProyectoForenseUIDE/
‚îú‚îÄ‚îÄ backend/                  # Flask API
‚îÇ   ‚îú‚îÄ‚îÄ app.py               # App Factory (Registered all blueprints)
‚îÇ   ‚îú‚îÄ‚îÄ routes/              # API Endpoints
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ analyze.py       # Image analysis
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ analyze_video.py # Video analysis [NEW 3.4]
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ analyze_audio.py # Audio analysis [NEW 3.4]
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ semantic.py      # Debug/Test routes
‚îÇ   ‚îú‚îÄ‚îÄ services/            # Business Logic
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ forensics_pipeline.py  # Image orchestrator
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ deepseek_client.py     # LLM client
‚îÇ   ‚îî‚îÄ‚îÄ uploads/             # Temporary file storage
‚îÇ
‚îú‚îÄ‚îÄ frontend/                # React App
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ UploadImage.jsx      # Image upload
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ UploadVideo.jsx      # Video upload [NEW 3.4]
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ UploadAudio.jsx      # Audio upload [NEW 3.4]
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ResultCard.jsx       # Image results
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ VideoResultCard.jsx  # Video results [NEW 3.4]
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ AudioResultCard.jsx  # Audio results [NEW 3.4]
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ api.js       # API client (analyzeImage/Video/Audio)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ App.jsx          # Main layout (tabs: image/video/audio)
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ
‚îú‚îÄ‚îÄ modules/                 # Core AI Modules
‚îÇ   ‚îú‚îÄ‚îÄ image_forensics/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fusion_engine.py       # V3.3 calibrated weights
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ semantic_expert.py     # DeepSeek-R1 integration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ feature_extractor.py   # CLIP embeddings
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îú‚îÄ‚îÄ video_forensics.py   # XceptionNet detector [REFACTORED]
‚îÇ   ‚îî‚îÄ‚îÄ audio_forensics.py   # HuggingFace AST detector
‚îÇ
‚îú‚îÄ‚îÄ config.py                # Centralized configuration
‚îÇ   ‚îú‚îÄ‚îÄ Video: MAX_VIDEO_SIZE_MB, VIDEO_THRESHOLD, etc.
‚îÇ   ‚îî‚îÄ‚îÄ Audio: AUDIO_SAMPLE_RATE, MODEL_AUDIO_NAME, etc.
‚îÇ
‚îî‚îÄ‚îÄ app.py                   # [LEGACY] Old Gradio app (deprecated)
```

---

## ‚öôÔ∏è Configuraci√≥n (config.py + .env)

### Video Settings
```python
SUPPORTED_VIDEO_FORMATS = {'.mp4', '.avi', '.mov', '.mkv'}
MAX_VIDEO_SIZE_MB = 100
MAX_VIDEO_DURATION_SECONDS = 120
VIDEO_FRAME_STRIDE = 30  # Analyze 1 frame every 30
MIN_FACES_REQUIRED = 5
VIDEO_THRESHOLD = 50.0   # Deepfake probability threshold
```

### Audio Settings
```python
SUPPORTED_AUDIO_FORMATS = {'.mp3', '.wav', '.m4a', '.ogg', '.flac'}
MAX_AUDIO_SIZE_MB = 20
AUDIO_SAMPLE_RATE = 16000
AUDIO_MAX_DURATION = 60
MODEL_AUDIO_NAME = "MIT/ast-finetuned-audioset-10-10-0.4593"
```

### Environment Variables (.env)
```env
# Flask
FLASK_ENV=production
FLASK_SECRET_KEY=...

# DeepSeek / Ollama (for image semantic analysis)
DEEPSEEK_ENABLED=true
DEEPSEEK_API_URL=http://localhost:11434/api/generate
DEEPSEEK_MODEL=deepseek-r1:7b

# CORS
CORS_ORIGINS=http://localhost:5173,https://midominio.com
```

---

## üñºÔ∏è Image Forensics Module (V12.0 Trinity Judgment)

**Files**: `modules/image_forensics/` directory, `backend/services/forensics_pipeline.py`

### Architecture - Trinity Judgment System

El an√°lisis de im√°genes usa un **sistema de juicio en 4 etapas**:

**STAGE 1: PERITOS (Expert Collectors)** - Recolectan n√∫meros t√©cnicos:
1. **multiLID** (`multilid_expert.py`): Geometr√≠a - Dimensi√≥n Intr√≠nseca Local (0-1)
2. **UFD** (`ufd_expert.py`): Ruido visual - Artefactos en espacio CLIP (0-1)
3. **FFT** (`fft_expert.py`): Frecuencia - An√°lisis FFT de patrones (0-1)

**STAGE 2: VISION** - Descripci√≥n de imagen:
- **BLIP** (Salesforce): Genera descripci√≥n textual de la imagen

**STAGE 3: DOCTOR (DeepSeek Judge)** - Razonamiento contextual:
- **Semantic Expert** (`semantic_expert.py`) + **DeepSeek-R1**:
  - Lee n√∫meros t√©cnicos (MultiLID, UFD, FFT)
  - Lee descripci√≥n de imagen (BLIP)
  - Razona sobre plausibilidad sem√°ntica
  - Retorna score 0-1

**STAGE 4: SENTENCIA (Binary Verdict)** - Decisi√≥n final:
- **Fusion Engine V10.0** (`fusion_engine.py`):
  - Threshold binario: `> 0.60 = IA`, `‚â§ 0.60 = REAL`
  - Genera veredicto final y evidencias

### API Contract

**Endpoint**: `POST /api/analyze_image`

**Input**: `FormData` with `image` file
- Supported formats: PNG, JPG, JPEG, WEBP, BMP
- Max size: 10MB (configurable en `config.py`)

**Query Parameters** (opcional):
- `use_deepseek=true|false`: Habilitar/deshabilitar an√°lisis sem√°ntico con LLM

**Output**:
```json
{
  "status": "success",
  "result": {
    "verdict": "GENERADA POR IA",
    "confidence": "ALTA",
    "overall_synthetic_score": 0.78,
    "experts": {
      "multilid": {
        "score": 0.23,
        "interpretation": "Geometr√≠a consistente con IA generativa"
      },
      "ufd": {
        "score": 0.67,
        "interpretation": "Artefactos visuales detectados"
      },
      "semantic": {
        "score": 0.85,
        "improbability": 0.72,
        "collision": 0.45,
        "composition": 0.68,
        "reasoning": "Simetr√≠a perfecta antinatural...",
        "enabled": true
      }
    },
    "fusion": {
      "weighted_score": 0.78,
      "weights": {"multilid": 0.35, "ufd": 0.25, "semantic": 0.40},
      "evidence_ia": 0.52,
      "evidence_real": 0.08,
      "decision_path": "HARD_THRESHOLD_SEMANTIC"
    },
    "clip_probabilities": {
      "ai_generated": 0.82,
      "real_photo": 0.18
    }
  },
  "processing_time": 3.2,
  "deepseek_enabled": true
}
```

**Error Response**:
```json
{
  "error": "File type not allowed. Supported: png, jpg, jpeg, webp, bmp",
  "status": "error"
}
```

### Key Features (V12.0)

- ‚úÖ **Trinity Judgment System**: Peritos (3 expertos) + Vision (BLIP) + Doctor (DeepSeek) + Sentencia (Fusion)
- ‚úÖ **Binary Decision**: Threshold 0.60 para veredicto definitivo (IA o REAL)
- ‚úÖ **Data-Driven DeepSeek**: LLM lee n√∫meros t√©cnicos + contexto visual
- ‚úÖ **FFT Integration**: An√°lisis frecuencial adem√°s de geometr√≠a y ruido
- ‚úÖ **BLIP Vision**: Descripci√≥n autom√°tica de imagen para contexto sem√°ntico

---

## üé• Video Forensics Module


**File**: `modules/video_forensics.py`

### Key Changes in 3.4
- ‚ùå Removed: Gradio dependencies (`gr.Progress`, generator pattern with `yield`)
- ‚úÖ Added: Direct dictionary return for REST API compatibility
- ‚úÖ Kept: XceptionNet model, face detection, Top-K frame selection

### API Contract
**Endpoint**: `POST /api/analyze_video`
**Input**: `FormData` with `video` file
**Output**:
```json
{
  "status": "success",
  "result": {
    "is_deepfake": true,
    "probability": 67.8,
    "verdict": "DEEPFAKE",
    "frames_total": 120,
    "frames_analyzed": 45,
    "duration": 4.0,
    "max_probability": 89.2,
    "predictions": [[0, 45.2], [30, 67.8], ...]
  },
  "processing_time": 12.3
}
```

---

## üîä Audio Forensics Module

**File**: `modules/audio_forensics.py`

### Key Features
- Already compatible with REST API (no Gradio dependencies)
- Uses HuggingFace `transformers` library
- Detects ElevenLabs, RVC, TTS, and other synthetic voices

### API Contract
**Endpoint**: `POST /api/analyze_audio`
**Input**: `FormData` with `audio` file
**Output**:
```json
{
  "status": "success",
  "result": {
    "verdict": "AUDIO SINT√âTICO",
    "score": 78.5,
    "confidence": 92.1,
    "duration_analyzed": 3.5,
    "sample_rate": 16000,
    "top_classes": [
      {"label": "Speech synthesizer", "score": 0.785},
      {"label": "Human voice", "score": 0.215}
    ]
  },
  "processing_time": 4.2
}
```

---

## üß† Semantic Expert (DeepSeek-R1) - Doctor Stage in V12.0

**File**: `modules/image_forensics/semantic_expert.py`
**Client**: `backend/services/deepseek_client.py`

En V12.0, el Semantic Expert act√∫a como **"Doctor" (Juez)**:
- **Input**: N√∫meros t√©cnicos (MultiLID, UFD, FFT) + Descripci√≥n BLIP
- **Process**: DeepSeek-R1 razona sobre plausibilidad (contexto sem√°ntico + n√∫meros)
- **Output**: Score √∫nico 0-1 que alimenta al Fusion Engine

**Workflow**:
1. Recibe context dict: `{"multilid": 0.23, "ufd": 0.67, "fft": 0.45}`
2. Recibe descripci√≥n: `"a photo of a person holding a cat"`
3. DeepSeek analiza: ¬øEs plausible? ¬øLos n√∫meros coinciden con descripci√≥n?
4. Retorna: `score 0-1` (1 = muy sint√©tico, 0 = muy real)

---

## ‚öóÔ∏è Fusion Engine V10.0 - Sentencia (Binary Logic)

**File**: `modules/image_forensics/fusion_engine.py`

Sistema de decisi√≥n binaria simple:

```python
# V10.0 Binary Decision
if semantic_score > 0.60:
    verdict = "GENERADA POR IA"
else:
    verdict = "REAL"
```

**L√≥gica**:
- **Threshold**: 0.60 (binario, sin zonas grises)
- **Input**: Solo semantic_score (DeepSeek ya consider√≥ MultiLID, UFD, FFT)
- **Output**: Veredicto definitivo + evidencias

**Rationale**: DeepSeek ya fusion√≥ toda la informaci√≥n t√©cnica en su razonamiento, el Fusion Engine solo aplica threshold binario para veredicto final.

---

## üöÄ Deployment

### Development
```bash
# Backend
cd backend
python app.py  # http://localhost:5000

# Frontend
cd frontend
npm run dev    # http://localhost:5173
```

### Production
```bash
# Backend (Gunicorn)
gunicorn -c backend/gunicorn_config.py backend.wsgi:app

# Frontend (Build)
cd frontend && npm run build
# Serve dist/ with Nginx or similar
```

---

## üìä Migration Status (V15.0)

| Feature | Status | Notes |
| :--- | :--- | :--- |
| Image Analysis (V12.0 Trinity) | ‚úÖ Complete | Peritos + Vision + Doctor + Sentencia |
| Video Deepfake Detection | ‚úÖ Complete | XceptionNet, refactored for REST API |
| Audio Synthetic Detection | ‚úÖ Complete | HuggingFace AST |
| React + Flask Architecture | ‚úÖ Complete | Clean separation, modular routes |
| Gradio Legacy App | ‚ö†Ô∏è Deprecated | `app.py` in root (not used) |
| DeepSeek-R1 Integration | ‚úÖ Active | Doctor stage in Trinity Judgment |
| FFT Expert | ‚úÖ Active | Frequency analysis (Perito #3) |
| BLIP Vision | ‚úÖ Active | Image description (Vision stage) |
| Fusion Engine V10.0 | ‚úÖ Active | Binary logic (Sentencia stage) |

---

## üéì Contexto del Proyecto
- **Organizaci√≥n**: UIDE (Universidad Internacional del Ecuador).
- **Objetivo**: Detecci√≥n de contenido sint√©tico con enfoque forense/legal.
- **Estado Actual**: Versi√≥n 15.0 completa. Trinity Judgment System (V12.0) con Fusion Engine V10.0, m√°s video y audio migrados a React + Flask.
